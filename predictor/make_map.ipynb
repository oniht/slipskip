{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from fmiopendata.wfs import download_stored_query\n",
    "\n",
    "# Retrieve the last 10 days daily observations + todays latest 10h observation\n",
    "end_time = dt.datetime.utcnow()\n",
    "start_time = end_time - dt.timedelta(days=10)\n",
    "start_time2 = end_time - dt.timedelta(hours=10)\n",
    "# Convert times to properly formatted strings\n",
    "start_time = start_time.isoformat(timespec=\"seconds\") + \"Z\"\n",
    "start_time2 = start_time2.isoformat(timespec=\"seconds\") + \"Z\"\n",
    "# -> 2020-07-07T12:00:00Z\n",
    "end_time = end_time.isoformat(timespec=\"seconds\") + \"Z\"\n",
    "# -> 2020-07-07T13:00:00Z\n",
    "\n",
    "# For last 10d we get daily values\n",
    "obs = download_stored_query(\"fmi::observations::weather::daily::multipointcoverage\",\n",
    "                            args=[\"place=kumpula\",\n",
    "                                  \"starttime=\" + start_time,\n",
    "                                  \"endtime=\" + end_time])\n",
    "\n",
    "# For last 10h we get all observations and use these to calculate the \"daily\" observations for today\n",
    "obs2 = download_stored_query(\"fmi::observations::weather::multipointcoverage\",\n",
    "                            args=[\"place=kumpula\",\n",
    "                                  \"starttime=\" + start_time2,\n",
    "                                  \"endtime=\" + end_time])\n",
    "\n",
    "df = pd.DataFrame.from_dict({(i): obs.data[i][j]\n",
    "                           for i in obs.data.keys() \n",
    "                           for j in obs.data[i].keys()},\n",
    "                       orient='index')\n",
    "df = df.applymap(lambda x: x.get('value'))\n",
    "\n",
    "dfh = pd.DataFrame.from_dict({(i): obs2.data[i][j]\n",
    "                           for i in obs2.data.keys() \n",
    "                           for j in obs2.data[i].keys()},\n",
    "                       orient='index')\n",
    "dfh = dfh.applymap(lambda x: x.get('value'))\n",
    "\n",
    "# We have to calculate some new columns for these more frequent observations\n",
    "dfh['Minimum temperature'] = dfh['Air temperature'].min()\n",
    "dfh['Maximum temperature'] = dfh['Air temperature'].max()\n",
    "dfh['Air temperature'] = dfh['Air temperature'].mean()\n",
    "dfh['Ground minimum temperature'] = dfh['Minimum temperature']\n",
    "dfh = dfh.sort_index(axis=0, ascending=False).head(1)\n",
    "dfh = dfh[df.columns]\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.weather_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweather_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweather_data_trimming\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(f)\n\u001b[0;32m      5\u001b[0m df2 \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mrename_cols(df)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data.weather_data'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data.weather_data.weather_data_trimming as f\n",
    "importlib.reload(f)\n",
    "\n",
    "df2 = f.rename_cols(df)\n",
    "dfh2 = f.rename_cols(dfh)\n",
    "df2 = f.merge_and_replace(df2, dfh2)\n",
    "\n",
    "#print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.weather_feature_extraction as m\n",
    "importlib.reload(m)\n",
    "\n",
    "df3 = m.get_features(df2).sort_index(axis=0, ascending=False)\n",
    "X_pred = df3.head(1).fillna(0).to_numpy() #\n",
    "date = df3.head(1).index.item() + dt.timedelta(days=1)\n",
    "\n",
    "#print(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('/slipskip/model/random_forest_model')\n",
    "\n",
    "y_pred = model.predict(X_pred)\n",
    "y_prob = model.predict_proba(X_pred)\n",
    "print(date, y_pred, y_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc8430a40fbc827d38a9eb7a33e6235b87f482008d42fc8d130ebcfb90a224a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
